---
# Source: prometheus/templates/alertmanager-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "alertmanager"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-alertmanager
data:
  alertmanager.yml: |
    global:
      smtp_auth_password: '*********'
      smtp_auth_username: xxxx@163.com
      smtp_from: xxxx@163.com
      smtp_require_tls: false
      smtp_smarthost: smtp.163.com:25
    receivers:
    - email_configs:
      - to: xxxx@163.com
      name: AlertMail
    - name: dingtalk
      webhook_configs:
      - send_resolved: false
        url: http://webhook-dingtalk.monitoring.svc.cluster.local:8060/dingtalk/webhook1/send
    route:
      group_by:
      - alertname
      - pod_name
      group_interval: 5m
      group_wait: 10s
      receiver: dingtalk
      repeat_interval: 3h
    
---
# Source: prometheus/templates/server-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "server"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-server
data:
  alerts: |
    groups:
    - name: k8s_alert_rules
      rules:
      - alert: container_mem_over_90
        annotations:
          description: Memory Usage of Pod {{ $labels.pod_name }} on {{ $labels.kubernetes_io_hostname
            }} has exceeded 90% for more than 2 minutes.
          summary: '{{ $labels.pod_name }}''s memory usage alert'
        expr: (sum(container_memory_working_set_bytes{image!="",name=~"^k8s_.*", pod_name!=""})
          by (pod_name)) / (sum (container_spec_memory_limit_bytes{image!="",name=~"^k8s_.*",
          pod_name!=""}) by (pod_name)) > 0.9 and (sum(container_memory_working_set_bytes{image!="",name=~"^k8s_.*",
          pod_name!=""}) by (pod_name)) / (sum (container_spec_memory_limit_bytes{image!="",name=~"^k8s_.*",
          pod_name!=""}) by (pod_name)) < 2
        for: 2m
      - alert: node_down
        annotations:
          description: Node {{ $labels.kubernetes_io_hostname }} is down
          summary: Node {{ $labels.kubernetes_io_hostname }} is down
        expr: up == 0
        for: 60s
    
  prometheus.yml: |
    global:
      evaluation_interval: 1m
      scrape_interval: 2s
      scrape_timeout: 1s
      
    rule_files:
    - /etc/config/rules
    - /etc/config/alerts
    scrape_configs:
    - job_name: prometheus
      static_configs:
      - targets:
        - localhost:9090
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-apiservers
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: default;kubernetes;https
        source_labels:
        - __meta_kubernetes_namespace
        - __meta_kubernetes_service_name
        - __meta_kubernetes_endpoint_port_name
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/${1}/proxy/metrics
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      job_name: kubernetes-nodes-cadvisor
      kubernetes_sd_configs:
      - role: node
      relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - replacement: kubernetes.default.svc:443
        target_label: __address__
      - regex: (.+)
        replacement: /api/v1/nodes/${1}/proxy/metrics/cadvisor
        source_labels:
        - __meta_kubernetes_node_name
        target_label: __metrics_path__
      scheme: https
      tls_config:
        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        insecure_skip_verify: true
    - job_name: kubernetes-service-endpoints
      kubernetes_sd_configs:
      - role: endpoints
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scrape
      - action: replace
        regex: (https?)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_scheme
        target_label: __scheme__
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_service_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
    - honor_labels: true
      job_name: prometheus-pushgateway
      kubernetes_sd_configs:
      - role: service
      relabel_configs:
      - action: keep
        regex: pushgateway
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
    - job_name: kubernetes-services
      kubernetes_sd_configs:
      - role: service
      metrics_path: /probe
      params:
        module:
        - http_2xx
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_service_annotation_prometheus_io_probe
      - source_labels:
        - __address__
        target_label: __param_target
      - replacement: blackbox
        target_label: __address__
      - source_labels:
        - __param_target
        target_label: instance
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - source_labels:
        - __meta_kubernetes_service_name
        target_label: kubernetes_name
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - action: keep
        regex: true
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_scrape
      - action: replace
        regex: (.+)
        source_labels:
        - __meta_kubernetes_pod_annotation_prometheus_io_path
        target_label: __metrics_path__
      - action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        source_labels:
        - __address__
        - __meta_kubernetes_pod_annotation_prometheus_io_port
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - action: replace
        source_labels:
        - __meta_kubernetes_namespace
        target_label: kubernetes_namespace
      - action: replace
        source_labels:
        - __meta_kubernetes_pod_name
        target_label: kubernetes_pod_name
    
    alerting:
      alertmanagers:
      - kubernetes_sd_configs:
          - role: pod
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace]
          regex: monitoring
          action: keep
        - source_labels: [__meta_kubernetes_pod_label_app]
          regex: prometheus
          action: keep
        - source_labels: [__meta_kubernetes_pod_label_component]
          regex: alertmanager
          action: keep
        - source_labels: [__meta_kubernetes_pod_container_port_number]
          regex:
          action: drop
  rules: |
    {}
    
---
# Source: prometheus/templates/alertmanager-serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "alertmanager"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-alertmanager

---
# Source: prometheus/templates/kube-state-metrics-serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "kube-state-metrics"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-kube-state-metrics

---
# Source: prometheus/templates/node-exporter-serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "node-exporter"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-node-exporter

---
# Source: prometheus/templates/pushgateway-serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "pushgateway"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-pushgateway

---
# Source: prometheus/templates/server-serviceaccount.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "server"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-server

---
# Source: prometheus/templates/kube-state-metrics-clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "kube-state-metrics"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-kube-state-metrics
rules:
  - apiGroups:
      - ""
    resources:
      - namespaces
      - nodes
      - persistentvolumeclaims
      - pods
      - services
      - resourcequotas
      - replicationcontrollers
      - limitranges
      - persistentvolumeclaims
      - persistentvolumes
      - endpoints
      - secrets
      - configmaps
    verbs:
      - list
      - watch
  - apiGroups:
      - extensions
    resources:
      - daemonsets
      - deployments
      - replicasets
    verbs:
      - list
      - watch
  - apiGroups:
      - apps
    resources:
      - statefulsets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - batch
    resources:
      - cronjobs
      - jobs
    verbs:
      - list
      - watch
  - apiGroups:
      - autoscaling
    resources:
      - horizontalpodautoscalers
    verbs:
      - list
      - watch

---
# Source: prometheus/templates/server-clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "server"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-server
rules:
  - apiGroups:
      - ""
    resources:
      - nodes
      - nodes/proxy
      - services
      - endpoints
      - pods
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
  - apiGroups:
      - "extensions"
    resources:
      - ingresses/status
      - ingresses
    verbs:
      - get
      - list
      - watch
  - nonResourceURLs:
      - "/metrics"
    verbs:
      - get

---
# Source: prometheus/templates/kube-state-metrics-clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "kube-state-metrics"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-kube-state-metrics
subjects:
  - kind: ServiceAccount
    name: monitor-prometheus-kube-state-metrics
    namespace: monitoring
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: monitor-prometheus-kube-state-metrics

---
# Source: prometheus/templates/server-clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "server"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-server
subjects:
  - kind: ServiceAccount
    name: monitor-prometheus-server
    namespace: monitoring
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: monitor-prometheus-server

---
# Source: prometheus/templates/alertmanager-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "alertmanager"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-alertmanager
spec:
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 9093
      nodePort: 39001
  selector:
    app: prometheus
    component: "alertmanager"
    release: monitor
  type: "NodePort"

---
# Source: prometheus/templates/kube-state-metrics-svc.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
    
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "kube-state-metrics"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-kube-state-metrics
spec:
  clusterIP: None
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8080
  selector:
    app: prometheus
    component: "kube-state-metrics"
    release: monitor
  type: "ClusterIP"

---
# Source: prometheus/templates/node-exporter-service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/scrape: "true"
    
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "node-exporter"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-node-exporter
spec:
  clusterIP: None
  ports:
    - name: metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
  selector:
    app: prometheus
    component: "node-exporter"
    release: monitor
  type: "ClusterIP"
---
# Source: prometheus/templates/server-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "server"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-server
spec:
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 9090
      nodePort: 39000
  selector:
    app: prometheus
    component: "server"
    release: monitor
  type: "NodePort"

---
# Source: prometheus/templates/node-exporter-daemonset.yaml
apiVersion: apps/v1 
kind: DaemonSet
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "node-exporter"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-node-exporter
spec:
  selector:
    matchLabels:
      app: prometheus
      component: "node-exporter"
      release: monitor
  updateStrategy:
    type: OnDelete
    
  template:
    metadata:
      labels:
        app: prometheus
        component: "node-exporter"
        release: monitor
    spec:
      serviceAccountName: monitor-prometheus-node-exporter
      containers:
        - name: prometheus-node-exporter
          image: "prom/node-exporter:v0.15.2"
          imagePullPolicy: "IfNotPresent"
          args:
            - --path.procfs=/host/proc
            - --path.sysfs=/host/sys
          ports:
            - name: metrics
              containerPort: 9100
              hostPort: 9100
          resources:
            {}
            
          volumeMounts:
            - name: proc
              mountPath: /host/proc
              readOnly:  true
            - name: sys
              mountPath: /host/sys
              readOnly: true
      hostNetwork: true
      hostPID: true
      tolerations:
        - effect: NoSchedule
          key: AcceptType
          operator: Equal
          value: SysTool
        
      volumes:
        - name: proc
          hostPath:
            path: /proc
        - name: sys
          hostPath:
            path: /sys
---
# Source: prometheus/templates/alertmanager-deployment.yaml
apiVersion: apps/v1 
kind: Deployment
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "alertmanager"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-alertmanager
spec:
  selector:
    matchLabels:
      app: prometheus
      component: "alertmanager"
      release: monitor
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
        component: "alertmanager"
        release: monitor
    spec:
      serviceAccountName: monitor-prometheus-alertmanager
      containers:
        - name: prometheus-alertmanager
          image: "prom/alertmanager:v0.15.2"
          imagePullPolicy: "IfNotPresent"
          env:
          args:
            - --config.file=/etc/config/alertmanager.yml
            - --storage.path=/data
            - --web.external-url=/

          ports:
            - containerPort: 9093
          readinessProbe:
            httpGet:
              path: /#/status
              port: 9093
            initialDelaySeconds: 30
            timeoutSeconds: 30
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: "/data"
              subPath: ""

        - name: prometheus-alertmanager-configmap-reload
          image: "jimmidyson/configmap-reload:v0.2.2"
          imagePullPolicy: "IfNotPresent"
          args:
            - --volume-dir=/etc/config
            - --webhook-url=http://localhost:9093/-/reload
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
              readOnly: true
      # nodeSelector:
        # kubernetes.io/hostname: 10.0.0.252
        
      tolerations:
        - effect: NoSchedule
          key: AcceptType
          operator: Equal
          value: SysTool
        
      volumes:
        - name: config-volume
          configMap:
            name: monitor-prometheus-alertmanager
        - name: storage-volume
          emptyDir: {}

---
# Source: prometheus/templates/kube-state-metrics-deployment.yaml
apiVersion: apps/v1 
kind: Deployment
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "kube-state-metrics"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-kube-state-metrics
spec:
  selector:
    matchLabels:
      app: prometheus
      component: "kube-state-metrics"
      release: monitor
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
        component: "kube-state-metrics"
        release: monitor
    spec:
      serviceAccountName: monitor-prometheus-kube-state-metrics
      containers:
        - name: prometheus-kube-state-metrics
          image: "mirrorgooglecontainers/kube-state-metrics:v1.4.0"
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: metrics
              containerPort: 8080
          resources:
            {}
            
      # nodeSelector:
        # kubernetes.io/hostname: 10.0.0.252
        
      tolerations:
        - effect: NoSchedule
          key: AcceptType
          operator: Equal
          value: SysTool
        

---
# Source: prometheus/templates/server-deployment.yaml
apiVersion: apps/v1 
kind: Deployment
metadata:
  labels:
    app: prometheus
    chart: prometheus-7.1.4
    component: "server"
    heritage: Tiller
    release: monitor
  name: monitor-prometheus-server
spec:
  selector:
    matchLabels:
      app: prometheus
      component: "server"
      release: monitor
  replicas: 1
  template:
    metadata:
      labels:
        app: prometheus
        component: "server"
        release: monitor
    spec:
      serviceAccountName: monitor-prometheus-server
      initContainers:
      - name: "init-chown-data"
        image: "busybox:latest"
        imagePullPolicy: "IfNotPresent"
        resources:
            {}
            
        # 65534 is the nobody user that prometheus uses.
        command: ["chown", "-R", "65534:65534", "/data"]
        volumeMounts:
        - name: storage-volume
          mountPath: /data
          subPath: ""
      containers:
        - name: prometheus-server-configmap-reload
          image: "jimmidyson/configmap-reload:v0.2.2"
          imagePullPolicy: "IfNotPresent"
          args:
            - --volume-dir=/etc/config
            - --webhook-url=http://127.0.0.1:9090/-/reload
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
              readOnly: true

        - name: prometheus-server
          image: "prom/prometheus:v2.4.3"
          imagePullPolicy: "IfNotPresent"
          args:
            - --storage.tsdb.retention=1d
            - --config.file=/etc/config/prometheus.yml
            - --storage.tsdb.path=/data
            - --web.console.libraries=/etc/prometheus/console_libraries
            - --web.console.templates=/etc/prometheus/consoles
            - --web.enable-lifecycle
            - --web.enable-admin-api
          ports:
            - containerPort: 9090
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 30
            timeoutSeconds: 30
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 30
            timeoutSeconds: 30
          resources:
            {}
            
          volumeMounts:
            - name: config-volume
              mountPath: /etc/config
            - name: storage-volume
              mountPath: /data
              subPath: ""
      # nodeSelector:
        # kubernetes.io/hostname: 10.0.0.252
        
      tolerations:
        - effect: NoSchedule
          key: AcceptType
          operator: Equal
          value: SysTool
        - key: node.kubernetes.io/disk-pressure
          operator: Equal
          value: "True"
        
      terminationGracePeriodSeconds: 300
      volumes:
        - name: config-volume
          configMap:
            name: monitor-prometheus-server
        - name: storage-volume
          emptyDir: {}

---
# Source: prometheus/templates/alertmanager-ingress.yaml

---
# Source: prometheus/templates/alertmanager-networkpolicy.yaml


---
# Source: prometheus/templates/alertmanager-pvc.yaml

---
# Source: prometheus/templates/kube-state-metrics-networkpolicy.yaml


---
# Source: prometheus/templates/pushgateway-deployment.yaml


---
# Source: prometheus/templates/pushgateway-ingress.yaml

---
# Source: prometheus/templates/pushgateway-service.yaml


---
# Source: prometheus/templates/server-ingress.yaml

---
# Source: prometheus/templates/server-networkpolicy.yaml


---
# Source: prometheus/templates/server-pvc.yaml

